####  进程与线程的区别和联系（重点）

* 区别

1. 进程是对正在运行中的程序的一个抽象，进程是系统资源分配的基本单元，而线程是进程的子任务，是CPU任务调度和执行的基本单元。
2. 一个进程可以有多个线程，但是一个线程只能属于一个进程。
3. 每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的程序计数器（PC）、寄存器和栈，线程之间切换的开销小。
4. 进程之间不会相互影响；而一个线程崩溃会导致进程崩溃，从而影响同个进程里面的其他线程。

* 联系 进程与线程之间的关系：线程是存在进程的内部，一个进程中可以有多个线程，一个线程只能存在一个进程中。

进程和线程的切换比较:
(1)进程切换方式：切换虚拟地址空间，切换内核栈和硬件上下文
(2)线程切换方式：切换内核栈和硬件上下文
(3)虚拟地址空间的切换：切换页表,以使用新的地址空间，虚拟内存和物理内存会进行一一对应数据存放，页表（虚拟内存）可以将虚拟地址转换为物理内存地址，从而能够通过页表查找到虚拟地址空间的中的某一数据在物理内存的具体位置。
(4)页表切换的开销：通常使用TLB Cache来进行缓存常用的地址映射，用来加速页表查找，当进程切换后，页表页要进行切换，页表切换后TLB就会失效，Cache失效导致查找命中率降低，也就是虚拟地址转换为物理地址就会变慢，表现出来程序运行会慢
https://segmentfault.com/a/1190000019750164

#### 协程了解吗（高频）

协程又称为微线程。

协程（Coroutines），是一种基于线程之上，但又比线程更加轻量级的存在，协程的调度由用户控制，具有对内核来说不可见的特性。协程提供的挂起操作会使协程暂停执行，而不会导致线程阻塞。

- 协程可以比作子程序，但执行过程中，子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。协程之间的切换不需要涉及任何系统调用或任何阻塞调用
- 协程只在一个线程中执行，是子程序之间的切换，发生在用户态上。而且，线程的阻塞状态是由操作系统内核来完成，发生在内核态上，因此协程相比线程节省线程创建和切换的开销
- 协程中不存在同时写变量冲突，因此，也就不需要用来守卫关键区块的同步性原语，比如互斥锁、信号量等，并且不需要来自操作系统的支持。

协程就是子程序在执行时中断并转去执行别的子程序，在适当的时候又返回来执行。
这种子程序间的跳转不是函数调用，也不是多线程执行，所以省去了线程切换的开销，效率很高，并且不需要多线程间的锁机制，不会发生变量写冲突。

协程适用于IO阻塞且需要大量并发的场景，当发生IO阻塞，由协程的调度器进行调度，通过将数据流yield掉，并且记录当前栈上的数据，阻塞完后立刻再通过线程恢复栈，并把阻塞的结果放到这个线程上去运行。

#### 那协程的底层是怎么实现的，怎么使用协程？

协程进行中断跳转时将函数的上下文存放在其他位置中，而不是存放在函数堆栈里，当处理完其他事情跳转回来的时候，取回上下文继续执行原来的函数。

#### 什么时候用多进程，什么时候用多线程

https://blog.csdn.net/yu876876/article/details/82810178

* 频繁修改：需要频繁创建和销毁的优先使用**多线程**
* 计算量：需要大量计算的优先使用**多线程**  因为需要消耗大量CPU资源且切换频繁，所以多线程好一点
* 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用多进程。因为线程之间的数据共享和同步比较简单。
* 多分布：可能要扩展到多机分布的用**多进程**，多核分布的用**多线程**。

但是实际中更常见的是进程加线程的结合方式，并不是非此即彼的。

#### Linux理论上最多可以创建多少个进程？一个进程可以创建多少线程，和什么有关

32768，因为进程的pid是用pid_t(short类型)来表示的，pid_t的最大值是32768.所以理论上最多有32768个进程。

至于线程。进程最多可以创建的线程数是根据分配给调用栈的大小，以及操作系统（32位和64位不同）共同决定的。Linux32位下是300多个（一个进程的虚拟内存是4G，在Linux32位平台下，内核分走了1G，留给用户用的只有3G，如果创建一个线程分配的栈空间是10M，总共有3G内存可以使用，那么一个进程最多可以创建300个左右的线程）。64 位系统，用户态的虚拟空间大到有128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。

#### 冯诺依曼结构有哪几个模块？分别对应现代计算机的哪几个部分？（百度安全一面）

* 存储器：内存
* 控制器：南桥北桥
* 运算器：CPU
* 输入设备：键盘
* 输出设备：显示器、网卡

#### 进程之间的通信方法有哪几种 （重点）

进程之间的通信方式主要有六种，包括**管道，信号量，消息队列，信号，共享内存，套接字**。

- 管道：管道是半双工的，双方需要通信的时候，需要建立两个管道。管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据：管道一端的进程顺序地将进程数据写入缓冲区，另一端的进程则顺序地读取数据，该缓冲区可以看做一个循环队列，读和写的位置都是自动增加的，一个数据只能被读一次，读出以后再缓冲区都不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或写进程是否进入等待队列，当空的缓冲区有新数据写入或慢的缓冲区有数据读出时，就唤醒等待队列中的进程继续读写。管道是最容易实现的。

  匿名管道pipe和命名管道fifo除了建立，打开，删除的方式不同外，其余都是一样的。匿名管道只允许有亲缘关系的进程之间通信，也就是父子进程之间的通信，命名管道允许具有非亲缘关系的进程间通信。

- 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。信号量只有等待和发送两种操作。等待(P(sv))就是将其值减一或者挂起进程，发送(V(sv))就是将其值加一或者将进程恢复运行。

- 信号：信号是Linux系统中用于进程之间通信或操作的一种机制，信号可以在任何时候发送给某一进程，而无须知道该进程的状态。如果该进程并未处于执行状态，则该信号就由内核保存起来，直到该进程恢复执行并传递给它为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程。 信号是开销最小的。（如SIGINT：程序终止信号，程序运行过程中，按ctrl+c产生该信号；SIGBUS和SIGSEGV：进程访问非法地址；SIGKILL：用户终止进程执行信号，kill -9产生该信号）

- 共享内存：共享内存允许两个或多个进程共享一个给定的存储区（一块内存空间），这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，就像由malloc()分配的内存一样使用。一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取读出，从而实现了进程间的通信。共享内存的效率最高，缺点是没有提供同步机制，需要使用锁等其他机制进行同步。

- 消息队列：消息队列就是一个消息的链表，是保存在内核中的消息链表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。
  消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。
  可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。
  
- 套接字：套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。

#### 线程之间同步

临界资源：一次仅允许一个进程使用的资源。

- 临界区（Critical Section）：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。
- 互斥量（Mutex）：互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。
- 信号量（Semaphore）：允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。
- 事件（Event）: 用来通知线程有一些事件已发生，从而启动后继任务的开始。

* 管程：管理共享变量以及对共享变量的操作过程，让他们支持并发。

临界区不是内核对象，只能用于进程内部的线程同步，是用户方式的同步。互斥、信号量是内核对象，可以用于不同进程之间的线程同步（跨进程同步）

https://www.acwing.com/blog/content/7275/

#### 进程调度方法详细介绍

* 先来先服务 （FCFS first come first serve）：按照作业到达任务队列的顺序调度  FCFS是非抢占式的，易于实现，效率不高，性能不好，有利于长作业（CPU繁忙性）而不利于短作业（I/O繁忙性）。
* 短作业优先 （SHF short job first）：每次从队列里选择预计时间最短的作业运行。SJF是非抢占式的，优先照顾短作业，具有很好的性能，降低平均等待时间，提高吞吐量。但是不利于长作业，长作业可能一直处于等待状态，出现饥饿现象；完全未考虑作业的优先紧迫程度，不能用于实时系统。
* 最短剩余时间优先 该算法首先按照作业的服务时间挑选最短的作业运行，在该作业运行期间，一旦有新作业到达系统，并且该新作业的服务时间比当前运行作业的剩余服务时间短，则发生抢占；否则，当前作业继续运行。该算法确保一旦新的短作业或短进程进入系统，能够很快得到处理。
* 高响应比优先调度算法（Highest Reponse Ratio First, HRRF）是非抢占式的，主要用于作业调度。基本思想：每次进行作业调度时，先计算后备作业队列中每个作业的响应比，挑选最高的作业投入系统运行。响应比 = （等待时间 + 服务时间） / 服务时间 = 等待时间 / 服务时间 + 1。因为每次都需要计算响应比，所以比较耗费系统资源。
* 时间片轮转 用于分时系统的进程调度。基本思想：系统将CPU处理时间划分为若干个时间片（q），进程按照到达先后顺序排列。每次调度选择队首的进程，执行完1个时间片q后，计时器发出时钟中断请求，该进程移至队尾。以后每次调度都是如此。该算法能在给定的时间内响应所有用户的而请求，达到分时系统的目的。
* 多级反馈队列(Multilevel Feedback Queue) 

#### 进程的执行过程是什么样的，执行一个进程需要做哪些工作？

进程的执行需要经过三大步骤：编译，链接和装入。

* 编译：将源代码编译成若干模块
* 链接：将编译后的模块和所需要的库函数进行链接。链接包括三种形式：静态链接，装入时动态链接（将编译后的模块在链接时一边链接一边装入），运行时动态链接（在执行时才把需要的模块进行链接）
* 装入：将模块装入内存运行

https://blog.csdn.net/qq_38623623/article/details/78306498

将进程装入内存时，通常使用分页技术，将内存分成固定大小的页，进程分为固定大小的块，加载时将进程的块装入页中，并使用页表记录。减少外部碎片。

页表：操作系统会为每一个进程维护一个页表，页表主要记录其加载时每个块对应的页号。
分页的特点：不要求所有的块连续，可以避免外部碎片，但是会产生内部碎片。

通常操作系统还会使用虚拟内存的技术将磁盘作为内存的扩充。

#### 进程状态图

<img src="C:\Users\bairong\AppData\Roaming\Typora\typora-user-images\image-20220305200310958.png" alt="image-20220305200310958" style="zoom:80%;" />

#### 进程控制块（PCB）、进程地址空间

PCB就是进程控制块，是操作系统中的一种数据结构，用于表示进程状态，操作系统通过PCB对进程进行管理。

PCB中包含有：进程标识符，进程控制和管理信息（进程当前状态、进程优先级）、资源分配清单（用于说明有关内存地址空间或虚拟地址空间的状况，所打开文件的列表和所使用的输入/输出设备信息)和CPU相关信息（指CPU中各寄存器值，当进程被切换时，C P U状态信息都必须保存在相应的 P C B 中，以便进程重新执行时，能再从断点继续执行）。

进程地址空间内有：

* 代码段text：存放程序的二进制代码
* 初始化的数据Data：已经初始化且初值不为0的全局变量和静态局部变量
* 未初始化的数据BSS：还没有初始化的数据和初始值为0的数据
* 栈：存储函数局部变量
* 堆：存放进程运行时动态分配的内存

同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的。

#### 进程的上下文是怎么切换的

首先进程是由内核管理与调度的，所以 进程上下文切换 发生在内核态，进程上下文切换的内容包含用户空间资源（虚拟内存、栈、全局变量等）与内核空间资源（内核堆栈、寄存器等）。

在做上下文切换的时候，会把前一个进程的上下文保存到它的 PCB 中，然后加载当前进程的 PCB 上下文到 CPU 中，使得进程继续执行

线程的上下文切换其实就可以分为两种情况：

- 第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
- 第二种，前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

https://blog.csdn.net/weixin_39743357/article/details/110434038

#### 内核空间和用户空间是怎样区分的

在Linux中虚拟地址空间范围为0到4G，最高的1G地址（0xC0000000到0xFFFFFFFF）供内核使用，称为内核空间，低的3G空间（0x00000000到0xBFFFFFFF）供各个进程使用，就是用户空间。

内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。

#### 死锁产生的必要条件（怎么检测死锁，解决死锁问题）

（1） 互斥：一个资源每次只能被一个进程使用。
（2） 占有并等待：一个进程占有至少一个资源，并等待另一资源。
（3） 非抢占：进程已获得的资源，在末使用完之前不能被抢占。
（4） 循环等待：若干进程之间形成一种头尾相接的循环等待资源关系。

产生死锁的原因主要是：
（1） 因为系统资源不足。
（2） 进程运行推进的顺序不合适。
（3） 资源分配不当等。

## 处理死锁的方法

- 预防死锁：通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来防止死锁的发生。
- 避免死锁：在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免死锁的发生。
- 检测死锁：允许系统在运行过程中发生死锁，但可设置检测机构及时检测死锁的发生，并采取适当措施加以清除。
- 解除死锁：当检测出死锁后，便采取适当措施将进程从死锁状态中解脱出来。

#### 死锁的恢复

1. 重新启动：是最简单、最常用的死锁消除方法，但代价很大，因为在此之前所有进程已经完成的计算工作都将付之东流，不仅包括死锁的全部进程，也包括未参与死锁的全部进程。
2. 终止进程(process termination)：终止参与死锁的进程并回收它们所占资源。
   (1) 一次性全部终止；(2) 逐步终止(优先级，代价函数)
3. 剥夺资源(resource preemption):剥夺死锁进程所占有的全部或者部分资源。
   (1) 逐步剥夺：一次剥夺死锁进程所占有的一个或一组资源，如果死锁尚未解除再继续剥夺，直至死锁解除为止。
   (2) 一次剥夺：一次性地剥夺死锁进程所占有的全部资源。
4. 进程回退(rollback):让参与死锁的进程回退到以前没有发生死锁的某个点处，并由此点开始继续执行，希望进程交叉执行时不再发生死锁。但是系统开销很大：
   (1) 要实现“回退”，必须“记住”以前某一点处的现场，而现场随着进程推进而动态变化，需要花费大量时间和空间。
   (2) 一个回退的进程应当“挽回”它在回退点之间所造成的影响，如修改某一文件，给其它进程发送消息等，这些在实现时是难以做到的

#### 什么是饥饿

饥饿是由于资源分配策略不公引起的，当进程或线程无法访问它所需要的资源而不能继续执行时，就会发生饥饿现象。

#### 孤儿进程和僵尸进程分别是什么，怎么形成的？

https://www.cnblogs.com/Anker/p/3271773.html

* 孤儿进程是父进程退出后它的子进程还在执行，这时候这些子进程就成为孤儿进程。孤儿进程会被init进程收养并完成状态收集。
* 僵尸进程是指子进程完成并退出后父进程没有使用wait()或者waitpid()对它们进行状态收集，这些子进程的进程描述符仍然会留在系统中。这些子进程就成为僵尸进程。

#### linux的0号进程和1号进程

Linux下有3个特殊的进程，idle进程(PID = 0), init进程(PID = 1)和kthreadd(PID = 2)

**idle进程由系统自动创建, 运行在内核态**

idle进程其pid=0，其前身是系统创建的第一个进程，也是唯一一个没有通过fork()产生的进程。

**init进程由idle通过kernel_thread创建，在内核空间完成初始化后, 加载init程序, 并最终初始化用户空间**

1进程由0进程创建，完成系统的初始化. 是系统中所有其它用户进程的祖先进程。1进程会执行init函数，继续完成剩余的内核初始化，并在函数的最后调用execve系统调用，以装入用户空间的可执行程序/sbin/init，这时进程1就拥有了自己的属性资源，成为一个用户态1号进程(init进程)。至此，内核初始化和启动过程结束。下面就进入了用户空间的初始化，最后运行shell登陆界面。

 **kthreadd进程由idle通过kernel_thread创建，并始终运行在内核空间, 负责所有内核线程的调度和管理**

它的任务就是管理和调度其他内核线程kernel_thread, 会循环执行一个kthread的函数，该函数的作用就是运行kthread_create_list全局链表中维护的kthread, 当我们调用kernel_thread创建的内核线程会被加入到此链表中，因此所有的内核线程都是直接或者间接的以kthreadd为父进程。

#### 陷阱 中断 异常

**陷阱**指令可以使执行流程从用户态陷入内核并把控制权转移给操作系统，使得用户程序可以调用内核函数和使用硬件从而获得操作系统所提供的服务。

**中断**由处理器外部的硬件产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。

中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。

**异常**就是程序执行过程中的异常行为。比如除零异常，缓冲区溢出异常等。



Linux中断是指在CPU正常运行期间，由于内外部事件或由程序预先安排的事件引起的CPU暂时停止正在运行的程序，转而为该内部或外部事件或预先安排的事件服务的程序中去，服务完毕后再返回去继续运行被暂时中断的程序。

硬中断：硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。基于IRQ，CPU可以将相应的请求分发到对应的硬件驱动上。硬中断可以直接中断CPU，引起内核中相关的代码被触发。

软中断：软中断仅与内核相关，由当前正在运行的进程所产生。 通常，软中断是一些对I/O的请求，这些请求会调用内核中可以调度I/O发生的程序。 软中断并不会直接中断CPU，也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。 除了iowait(等待I/O的CPU使用率)升高，软中断(softirq)CPU使用率升高也是最常见的一种性能问题。

#### 异常和中断的区别

中断（interrupt）指在程序执行过程中遇到急需处理的事件时，暂时中止现行程序在 CPU 上的运行，转而执行响应的事件处理程序，待处理完成后再返回断点或调度其他程序。
**中断的原理**：中断分为软中断以及硬中断。**硬中断**也是外部中断，通常由IO设备通过中断总线发出的通知CPU。中断总线有两条，一条是可屏蔽中断，一条是不可屏蔽中断。可屏蔽中断CPU可以例会或者不理会，不可屏蔽中断，CPU必须进行处理。**软中断**是由软件主动发起的，通过特定的指令发出。而在程序执行过程中，发生错误的软中断，我们称为**异常**，比如除法的分母为0。

**中断/异常工作机制**：硬件和软件共同支持，硬件需要捕获响应并保存对应的类型到中断寄存器中，软件需要扫描中断寄存器，保留现场，并进行处理，执行中断程序以及恢复。

#### 为什么要区分用户态与内核态？

在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。所以，CPU将指令分为**特权指令和非特权指令**，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令。避免用户程序直接对内核进行操作，保证了系统的稳定、安全、可靠。

Intel的CPU将特权级别分为4个级别：ring0、ring1、ring2、ring3。其中 ring 0 权限最高，可以使用所有CPU 指令集，ring3 权限最低，仅能使用常规CPU指令集，不能使用操作硬件资源的CPU指令集，比如IO读写、网卡访问、申请内存都不行，Linux系统仅采用ring0 和 ring3 这2个权限。

- 执行内核空间的代码，具有ring0保护级别，有对硬件的所有操作权限，可以执行所有CPU指令集，访问任意地址的内存，在内核模式下的任何异常都是灾难性的，将会导致整台机器停机。
- 在用户模式下，具有ring 3保护级别，代码没有对硬件的直接控制权限，也不能直接访问地址的内存，程序是通过调用系统接口(System Call APIs)来达到访问硬件和内存，在这种保护模式下，即时程序发生崩溃也是可以恢复的，在电脑上大部分程序都是在，用户模式下运行的。

#### 用户态与内核态的切换

- 保留用户态现场（上下文、寄存器、用户栈等）
- 复制用户态参数，用户栈切到内核栈，进入内核态
- 额外的检查（因为内核代码对用户不信任）
- 执行内核态代码
- 复制内核态代码执行结果，回到用户态
- 恢复用户态现场（上下文、寄存器、用户栈等）

什么情况会导致用户态到内核态切换

- 系统调用：用户态进程主动切换到内核态的方式，用户态进程通过系统调用向操作系统申请资源完成工作，例如 fork（）就是一个创建新进程的系统调用，系统调用的机制核心使用了操作系统为用户特别开放的一个中断来实现，如Linux 的 int 80h 中断，也可以称为软中断。
- 异常：当 CPU 在执行用户态的进程时，发生了一些没有预知的异常，这时当前运行进程会切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。
- 中断：当 CPU 在执行用户态的进程时，外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令，转到与中断信号对应的处理程序去执行，也就是切换到了内核态。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。

https://segmentfault.com/a/1190000039774784

#### 操作系统在对内存进行管理的时候需要做些什么?

- 操作系统负责内存空间的分配与回收。
- 操作系统需要提供某种技术从逻辑上对内存空间进行扩充。
- 操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。
- 操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰。

#### 操作系统的内存管理虚拟内存的了解

https://zhuanlan.zhihu.com/p/345281212

https://www.cnblogs.com/Przz/p/6876988.html

在运行一个进程的时候，它所需要的内存空间可能大于系统的物理内存容量。通常一个进程会有4G的空间，但是物理内存并没有这么大，所以这些空间都是虚拟内存，它的地址都是逻辑地址，每次在访问的时候都需要映射成物理地址。
当进程访问某个逻辑地址的时候，会去查看页表，如果页表中没有相应的物理地址，说明内存中没有这页的数据，发生缺页异常，这时候进程需要把数据从磁盘拷贝到物理内存中。如果物理内存已经满了，就需要覆盖已有的页，如果这个页曾经被修改过，那么还要把它写回磁盘。

虚拟内存是操作系统内存管理的一种技术，每个进程启动时，操作系统会提供一个独立的虚拟地址空间，这个地址空间是连续的，进程可以很方便的访问内存，这里的内存指的是访问虚拟内存。**虚拟内存的目的，一是方便进程进行内存的访问，二是可以使有限的物理内存运行一个比它大很多的程序。**

虚拟内存的基本思想：每个程序拥有自己的地址空间，这个空间被分割成很多块，每块称为一页，每一页地址都是连续的地址范围。这些页被映射到物理内存，但不要求是连续的物理内存，也不需要所有的页都映射到物理内存，而是按需分配，在程序片段需要分配内存时由硬件执行映射(通常是 MMU)，调入内存中执行。

https://www.cnblogs.com/peterYong/p/6556619.html

https://zhuanlan.zhihu.com/p/141602175

操作系统的内存管理包括物理内存管理和虚拟内存管理

* 物理内存管理包括交换与覆盖，分页管理，分段管理和段页式管理等；
* 虚拟内存管理包括虚拟内存的概念，页面置换算法，页面分配策略等；

（面试官这样问的时候，其实是希望你能讲讲虚拟内存）

#### 虚拟内存

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将物理内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。

这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

#### 内存管理

**覆盖与交换**是在多道程序环境下用来扩充内存的两种方法。

**内存覆盖**

- 将程序分为多个段,常用的段常驻内存,不常用的段需要时调入内存 
- 内存分为一个"固定区",若干个"覆盖区" 
- 需要常驻的放在"固定区",调入后不在调出(除非运行结束) 
- 不常用的段在即将要访问时放入"覆盖区"，替换覆盖区中原有的段

**内存交换**

把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到外存，把内存空间腾出来，这一过程又叫换出；把准备好竞争CPU运行的程序从外存移到内存，这一过程又称为换入。

**内存管理单元（MMU）**：负责从虚拟地址到物理地址的转换。

**分页**管理：将物理内存分为固定大小的块（称为帧），而将逻辑内存也分为同样大小的块（称为页）。由CPU生成的每个地址分为两个部分：页号和页偏移，页号作为页表中的索引。页表包含每页所在物理内存的基地址，这些基地址和页偏移的组合就形成了物理地址。

<img src="C:\Users\bairong\AppData\Roaming\Typora\typora-user-images\image-20220305210310180.png" alt="image-20220305210310180" style="zoom:50%;" />

若页表全部放在内存中，则存取一个数据或一条指令至少要访问两次内存：一次是访问页表，确定所存取的数据或指令的物理地址，第二次才根据该地址存取数据或指令。显然，这种方法比通常执行指令的速度慢了一半。

TLB（转换表缓冲区）是关联的快速内存，用来存放页表中的一小部分条目，以加速地址转换。当CPU产生逻辑地址后，其页号提交给TLB，如果找到页号，也就得到了帧号，并可用来访问内存。如果页号不在TLB中（TLB失效），那么就需要访问页表，在读出页表项后，同时将其存储TLB中，若TLB已满，则需要按照一定的算法对旧的页表项进行替换。

<img src="C:\Users\bairong\AppData\Roaming\Typora\typora-user-images\image-20220305210630532.png" alt="image-20220305210630532" style="zoom:50%;" />

有效-无效位：当该位有效时，表示相关的页既合法也在进程的逻辑地址空间内，否则为无效（不在进程的逻辑地址空间内）或者有效但是在磁盘上。

<img src="C:\Users\bairong\AppData\Roaming\Typora\typora-user-images\image-20220305210933937.png" alt="image-20220305210933937" style="zoom:50%;" />

**分段管理**

分页存储是从计算机的角度设计的，目的是为了提高内存的利用率，提升计算机的性能。分段存储的提出是考虑到程序员和用户，以满足方便编程、数据共享、信息保护、动态增长、动态链接的需要。

按照用户进程中的自然段划分逻辑空间。每个进程都有一张逻辑空间与内存空间映射的段表，其中每一个段表项对应进程的一个段，段表项记录该段在内存中的起始地址和段的长度。

<img src="https://gitee.com/MysticalYu/pic/raw/master/hexo/image-20200927081520616.png" alt="image-20200927081520616" style="zoom: 80%;" />

#### 抖动你知道是什么吗？它也叫颠簸现象

刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够)

#### Cache映射方式

- 直接相联映射：一个内存块地址只能映射到一个固定的cache 行。
- 全相联映射：一个内存块地址可以映射到cache中任意一行。
- 组相联映射：将cache中的行分组，一个内存块地址映射到固定的cache组中，但行的地址随意。

https://floral.github.io/2020/08/22/Cache%E6%98%A0%E5%B0%84%E6%9C%BA%E5%88%B6%E4%B8%8E%E9%80%BB%E8%BE%91%E5%AE%9E%E7%8E%B0/

#### page size

- 小页面会增加页表占用的内存、减小TLB的命中率
- 大页面会浪费内存空间，造成内存碎片，降低内存的利用率

#### 内部碎片与外部碎片

内部碎片：分配给某些进程的内存区域中有些部分没用上，常见于固定分配方式

内存总量相同，100M

固定分配，将100M分割成10块，每块10M，一个程序需要45M，那么需要分配5块，第五块只用了5M，剩下的5M就是内部碎片；

分段式分配，按需分配，一个程序需要45M，就给分片45MB，剩下的55M供其它程序使用，不存在内部碎片。

外部碎片：内存中某些空闲区因为比较小，而难以利用上，一般出现在内存动态分配方式中

分段式分配：内存总量相同，100M，比如，内存分配依次5M，15M，50M，25M，程序运行一段时间之后，5M，15M的程序运行完毕，释放内存，其他程序还在运行，再次分配一个10M的内存供其它程序使用，只能从头开始分片，这样，就会存在10M+5M的外部碎片

#### 内存映射（mmap）

将一个文件或者其它对象映射到进程的地址空间，对映射后的虚拟内存地址进行读写操作就如同对文件进行读写操作一样。

#### Buddy和Slab内存分配

Linux内核中引入了**伙伴系统算法**(buddy system)。把所有的空闲页面分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页面的内存块。最大可以申请1024个连续页面，对应4MB大小的连续内存。

假设要申请一个256个页框的块，先从256个页框的链表中查找空闲块，如果没有，就去512个页框的链表中找，找到了则将页框块分为2个256个页框的块，一个分配给应用，另外一个移到256个页框的链表中。如果512个页框的链表中仍没有空闲块，继续向1024个页框的链表查找，如果仍然没有，则返回错误。

在释放内存块时，会检测归还内存的伙伴内存块（大小相同，地址连续）是否空闲, 如果空闲就合并在一起, 不空闲就直接放回到合适的链表中。

伙伴算法中有一定的浪费现象，伙伴算法是按2的幂次方大小进行分配内存块，当然这样做是有原因的，即为了避免把大的内存块拆的太碎，更重要的是使分配和释放过程迅速。但是他也带来了不利的一面，如果所需内存大小不是2的幂次方，就会有部分页面浪费。

对于小块内存,一般采用**slab算法**。

![slab allocator](https://xnerv.wang/assets/memory-allocation-buddy-system-and-slab-allocator/slab.png)

slab结构的最高层是 cache_chain，是一个slab缓存（kmem_cache）的链表，每个kmem_cache都包含了一个 slabs 列表，这是一段连续的内存块（通常都是页面），存在3 种 slab：

- slabs_full: 完全分配的slab
- slabs_partial: 部分分配的slab
- slabs_empty: 空slab，或者没有对象被分配

slab是slab分配器的最小单位，在实现上一个slab由一个多个连续的物理页组成（通常只有一页），每个 slab 被分配为多个对象。单个slab可以在slab链表之间移动，例如当一个 slab中的所有对象都被使用完时，就要从slabs_partial中删除，同时插入到slabs_full中去。

slab 缓存分配器通过对类似大小的对象进行缓存而提供这种功能，从而避免了常见的碎片问题。slab分配器还支持通用对象的初始化，从而避免了为同一目而对一个对象重复进行初始化。最后，slab分配器还可以支持硬件缓存对齐和着色，这允许不同缓存中的对象占用相同的缓存行，从而提高缓存的利用率并获得更好的性能。

#### Linux中的PageCache和BufferCache

内存分布示意图

<img src="https://pic1.zhimg.com/80/v2-e295352c7273887832b6beb185597460_1440w.jpg" alt="img" style="zoom:80%;" />

buffer: 作为buffer cache的内存，是块设备的读写缓冲区，更靠近存储设备，或者直接就是disk的缓冲区。

cache: 作为page cache的内存，文件系统的cache，是memory的缓冲区。

**BufferCache**: 块缓冲，是对物理磁盘上的一个磁盘块进行的缓存，块大小为通常为1k，磁盘块也是磁盘的组织单位。设立buffer cache的目的是为在程序多次访问同一磁盘块时，减少访问时间。

读取数据具体流程是：先将磁盘块读入buffer cache，如果cache空间不够，会通过一定的策略将一些过时或多次未被访问的buffer cache清空。程序在下一次访问磁盘时首先查看是否在buffer cache找到所需块，命中可减少访问磁盘时间，不命中时需重新读入buffer cache。

对buffer cache的写分为两种，一是**直接写**，这是程序在写buffer cache后也写磁盘，要读时从buffer cache上读，二是**后台写**，程序在写完buffer cache后并不立即写磁盘，因为有可能程序在很短时间内又需要写文件，如果直接写，就需多次写磁盘了。这样效率很低，而是过一段时间后由后台写，减少了多次访磁盘的时间。

**PageCache**: 页缓冲，用来缓存文件数据，页大小通常为4K，由若干个磁盘块组成（物理上不一定连续）。缓存在Page Cache中的文件数据，能够更快的被用户读取。同时对于带buffer的写入操作，数据在写入到Page Cache中即可立即返回，而不需等待数据被实际持久化到磁盘，进而提高了上层应用读写文件的整体性能。

https://www.cnblogs.com/Courage129/p/14311675.html

#### swap分区

Linux 的交换分区（swap），或者叫内存置换空间（swap space），是磁盘上的一块区域，可以是一个分区，也可以是一个文件，或者是他们的组合。交换分区的作用是，当系统物理内存（DRAM）不够时，Linux 会将内存中不常访问的数据保存到 swap 上，这样系统就有更多的物理内存为各个进程服务，而当系统需要访问 swap 上存储的内容时，再将 swap 上的数据加载到内存中，也就是常说的 swap out 和 swap in。

#### 内存一致性模型

定义内存系统如何处理来自多个处理器的内存操作的一组规则

**顺序一致性（SC）**

- 所有处理器对于内存的读写操作的最终结果和按某种顺序执行的结果一样
- 一个处理器内的内存读写操作按程序声明顺序执行

顺序一致性要求一个处理器对变量的修改，能被其它处理器上后续的读操作看到。对于一个存在Cache和缓存一致性协议的计算机来说，这就意味着一个处理器在写变量之前，必须先在总线上发送通知，通知其他处理器将自己对应的副本置为失效，在收到其他处理器的完成置为失效操作的确认之后，该处理器才能执行写操作。这一操作的开销是比较大的。

**放松的内存一致性**

**TSO**：允许StoreLoad重排序

<img src="https://gfjiangly.github.io/images/image-20200217114212933.png" alt="image-20200217114212933" style="zoom: 80%;" />

在SC模型里，代码可能的执行顺序如下：

```
S1 S2 L1 L2
S1 L1 S2 L2
S1 L1 L2 S2
L1 L2 S1 S2
L1 S1 S2 L2
L1 S1 L2 S2
```

由于SC会严格按照顺序进行，最终我们看到的结果是至少有一个处理器的r1值为NEW，或者都为NEW。

在TSO模型里，由于store buffer的存在，L1和S1的store指令会被先放到store buffer里面，然后CPU会继续执行后面的load指令。Store buffer中的数据可能还没有来得及往存储器中写，这个时候我们可能看到C1和C2的r1都为0的情况。

**PSO**：在TSO基础之上，允许地址无关的StoreStore重排序。

CPU可以以非FIFO来处理store buffer缓冲区中的指令，CPU只保证地址相关指令在store buffer中才会以FIFO的形式进行处理，而其他的则可以乱序处理。

<img src="https://gfjiangly.github.io/images/image-20200217114651549.png" alt="image-20200217114651549" style="zoom:80%;" />

S1与S2是地址无关的store指令，cpu执行的时候都会将其推到store buffer中。如果这个时候flag在C1的cache中不存在，那么CPU会优先将S2的store执行完，然后等flag缓存到C1的cache之后，再执行store data=NEW指令。

这个时候可能的执行顺序：S2 L1 L2 S1

这样在C1将data设置为NEW之前，C2已经执行完，r2最终的结果会为0，而不是我们期望的NEW。

**RMO：宽松内存模型**

丧心病狂的芯片研发人员为了榨取更多的性能，在PSO模型基础上，更进一步的放宽了内存一致性模型，不仅允许store-load，store-store乱序。还进一步允许load-load，load-store乱序， 只要是地址无关的指令，在读写访问的时候都可以打乱所有load/store的顺序，这就是宽松内存模型（RMO）。

#### 缓存一致性

监听协议：使用共享总线连接多个处理器的私有缓存核内存，保证所有处理器的数据请求串行执行。任何处理器发出的数据请求将被广播给所有处理器的缓存控制器，所有处理器的缓存控制器都时刻监听着总线。

**MESI状态转换**

<img src="https://lipanpan.github.io/images/201610071221.png" alt="MESI状态转换图" style="zoom: 80%;" />



M：数据只在本处理器中有缓存，且已被修改，没有写回内存

E：数据只在本处理器中有缓存，没有被修改，与内存一致

S：数据在多个处理器中有缓存

I：数据在本处理器中的缓存无效

| 状态 | local read | local write |                       remote read                       |                      remote write                       |
| :--: | :--------: | :---------: | :-----------------------------------------------------: | :-----------------------------------------------------: |
|  M   |     M      |      M      | S (其它处理器读取，本处理器将缓存行写回主存，状态变为S) | I (其它处理器写入，本处理器将缓存行写回主存，状态变为I) |
|  E   |     E      |      M      |                            S                            |                            I                            |
|  S   |     S      |      M      |                            S                            |                            I                            |
|  I   |    S或E    |      M      |                            I                            |                            I                            |

Store Buffer：是一个先进先出的缓冲区，位于CPU和Cache之间，处理器把它想要写入内存中的值放入store buffer，然后继续去执行其它指令。当所有失效确认（Invalidate Acknowledge）都接收到时，数据才会最终被提交。

Invalidate Queues：处理器将收到的invalidate消息放入失效队列，立即返回invalidate ack，这样以便发起者能尽快做后面的事情，而该CPU可以通过Invalidate Queue中存放的数据物理地址对缓存行的失效行为进行后续处理，采用“延后执行”。

![image](https://www.hollischuang.com/wp-content/uploads/2018/08/cache_sync.png)

Store Forwarding：处理器可以尝试从store buffer中读取值。

写屏障：处理器在执行写屏障之后的指令之前，应先完成所有在store buffer中的写指令（所有写屏障指令之前的内存写操作对之后的命令都是可见的）

读屏障：处理器在执行读屏障之后的指令之前，应先完成所有在invalidate queue中的失效指令（所有读屏障指令之前的读操作对于之后的命令都是可见的）

https://www.cnblogs.com/xmzJava/p/11417943.html

https://blinkfox.github.io/2018/11/18/ruan-jian-gong-ju/cpu-duo-ji-huan-cun/







































